{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pr-abin/100-_problem_in_NLP/blob/main/ML_Notebook_6_PyTorch_Regression_FireForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "\n",
        "\n",
        "PyTorch is a freely available software library for machine learning that is utilized in a wide range of tasks related to understanding language and perception. It is actively employed by multiple teams at Meta Platforms, both for research purposes and in production settings. Numerous deep learning software solutions have been developed using PyTorch, such as **Tesla** Autopilot, **Uber**'s Pyro, **Hugging Face's Transformer**s, PyTorch Lightning, and Catalyst.\n",
        "\n",
        "**PyTorch offers two primary features:\n",
        "* tensor computing resembling NumPy and\n",
        "* the ability to construct and train deep neural networks. **"
      ],
      "metadata": {
        "id": "Ox3Hf80CLMNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device checking\n",
        "\n",
        "The code snippet below checks the availability of devices and sets the \"device\" variable for computation:\n",
        "\n"
      ],
      "metadata": {
        "id": "bYd9bHw7NM0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Print the selected device\n",
        "print(\"Selected device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKy-_UwyNUgU",
        "outputId": "ae02cd18-276a-4ac5-de60-bceecba249a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code uses the torch.cuda.is_available() function to check if a GPU is available. If a GPU is present, the \"device\" variable is set to use CUDA (GPU), otherwise, it is set to use the CPU. The selected device is then printed for confirmation."
      ],
      "metadata": {
        "id": "dxzUSXU9NuZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Tensor Operation by Torch"
      ],
      "metadata": {
        "id": "DcIrt2KwOmSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Create tensors\n",
        "matrix1 = torch.tensor([[3., 3.]], device=device)\n",
        "matrix2 = torch.tensor([[2.], [2.]], device=device)\n",
        "# The device parameter specifies the device (either CPU or GPU) on which the tensor should be stored.\n",
        "# Since the device variable was previously set based on the availability of a CUDA-enabled GPU,\n",
        "#the tensor will be stored on that GPU if available, otherwise on the CPU.\n",
        "\n",
        "# Perform matrix multiplication\n",
        "product = torch.mm(matrix2, matrix1)\n",
        "\n",
        "# Print the product\n",
        "print(device)\n",
        "print(product)\n",
        "print(float(product[0, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_POf3VrN0YM",
        "outputId": "9208c7f0-7079-4fdc-d01a-04ded9133419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([[6., 6.],\n",
            "        [6., 6.]], device='cuda:0')\n",
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Subtraction:"
      ],
      "metadata": {
        "id": "2AKxFjExOuSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Create tensors\n",
        "x = torch.tensor([1.0, 2.0], device=device)\n",
        "a = torch.tensor([3.0, 3.0], device=device)\n",
        "\n",
        "# Subtract 'a' from 'x'\n",
        "sub = torch.subtract(x, a)\n",
        "\n",
        "# Print the result\n",
        "print(sub)\n",
        "print(float(sub)) # this gives error!\n",
        "#print(sub.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "hC0rGmexPKzh",
        "outputId": "3bba6f21-3493-4abf-c9f8-fbc5cf951e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2., -1.], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6617c87650ef>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this gives error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#print(sub.cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why it gives error? **\n",
        "\n",
        "With this no error, try it: print(sub.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "1Y5_SDiaPmK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What does it mean: sub.cpu().numpy()\n",
        "\n",
        " In order to use NumPy with a PyTorch tensor, we need to bring the tensor back to the CPU using the cpu() method and then call numpy() to access the tensor as a NumPy array. If the tensor is already on the CPU, the cpu() function has no effect and simply returns the tensor as is."
      ],
      "metadata": {
        "id": "E4xyWPzwP7sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of using PyTorch on a math operation:"
      ],
      "metadata": {
        "id": "3-9kqhuD3OZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a range of values for the x-axis\n",
        "x = torch.linspace(-5, 5, 100)\n",
        "\n",
        "# Define the mathematical shape (in this case, a parabola)\n",
        "y = x**2\n",
        "\n",
        "# Convert tensors to NumPy arrays\n",
        "x_np = x.numpy()\n",
        "y_np = y.numpy()\n",
        "\n",
        "# Plot the shape\n",
        "plt.plot(y_np, x_np)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Parabola')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "pUd7ZFhxzA2y",
        "outputId": "47270032-f764-4994-a083-82e2f5df0ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first create a range of values for the x-axis using torch.linspace to generate 100 equally spaced points between -5 and 5. We then define the mathematical shape, in this case, a parabola, by squaring the x values. Next, we convert the tensors x and y to NumPy arrays using the numpy() method. Finally, we use Matplotlib to plot the shape, setting labels for the x-axis and y-axis, adding a title, enabling gridlines, and displaying the plot with plt.show()."
      ],
      "metadata": {
        "id": "D199da81zUlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A regression Example by Pytorch\n",
        "\n",
        "Here we have applied the regression on a the fireforest dataset:\n",
        "https://data.heatonresearch.com/data/t81-558/forestfires.csv\n",
        "\n",
        "Different parameters have been given, and using ML, we predict the burnt area by fire for each location!\n",
        "\n",
        "Similar approach can be applied for predicting the abalone age:\n",
        "https://data.heatonresearch.com/data/t81-558/abalone.csv\n",
        "That is your assignmen, you should do it by modifying the same Colabnotebook, save this colabnotebook, and uploaded it on your own google drive, then modify it for predicting the age of abalone.\n",
        "\n",
        "Predicting the age of abalone is from physical measurements.  The age of abalone is determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope -- a boring and time-consuming task.  Other measurements, which are easier to obtain, are used to predict the age.  Further information, such as weather patterns and location (hence food availability) may be required to solve the problem.\n",
        "\n",
        "From the original data examples with missing values were removed (the majority having the predicted value missing), and the ranges of the continuous values have been scaled for use with an ANN (by dividing by 200).\n"
      ],
      "metadata": {
        "id": "4ahcphUA3h18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# finding the device under use:\n",
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Print the selected device\n",
        "print(\"Selected device:\", device)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# imports the train_test_split function from the model_selection module of the sklearn package\n",
        "# train_test_split is a function commonly used for splitting datasets into training and testing subsets.\n",
        "from sklearn.metrics import accuracy_score\n",
        "# accuracy_score is a function used to calculate the accuracy of a classification model by comparing the predicted labels with the true labels.\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "#  nn is a sub-package of PyTorch that provides various classes and functions for building neural networks.\n",
        "import torch.nn.functional as F\n",
        "# torch.nn.functional provides various activation functions, loss functions, ...\n",
        "import numpy as np\n",
        "from torch.autograd import Variable #  for automatic differentiation\n",
        "from sklearn import preprocessing # for preprocessing and transforming data before feeding it into models.\n",
        "# It includes scaling, standardizing, encoding categorical variables, and more\n",
        "\n",
        "# You will create a network class for every PyTorch neural network you create.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, out_count):\n",
        "        super(Net, self).__init__() # initializing the Net from the super class.\n",
        "        # We must define each of the layers.\n",
        "        self.fc1 = nn.Linear(in_count, 50)\n",
        "        self.fc2 = nn.Linear(50, 25)\n",
        "        self.fc3 = nn.Linear(25, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # In the forward pass, we must calculate all of the layers we\n",
        "        # previously defined.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "icFpk0eg4OjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a43cde-3b7f-4445-d83c-55c01e349434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The structure of your neural network is defined in the above **Net** class. The specific name of the class is not significant; however, it must inherit from **nn.Module** and implement the **init** and **forward** methods.\n",
        "\n",
        "Within the init method, you define the layers of the neural network. In this case, the network has an input layer that matches the number of inputs specified from the dataset. These inputs are then connected to 50 neurons in the first hidden layer, which in turn connect to 25 neurons in the second layer. It is important to ensure that the number of output neurons in a layer matches the number of input neurons in the subsequent layer."
      ],
      "metadata": {
        "id": "4im2lcWD4gDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **forward** method plays a crucial role in connecting the layers and specifying the activation functions in your neural network. In our case, we will consistently use the ReLU activation function for the hidden layers. However, **for the output layer of a regression neural network, no activation function is applied**. When it comes to **classification tasks, we utilize the logistic function for binary classification** (involving two classes only) or the **softmax function for classification problems with two or more classes**."
      ],
      "metadata": {
        "id": "1Py6Qa8A55rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order for the neural network to function properly, several factors must align.\n",
        "\n",
        "* Firstly, the **init** method should define the layers with matching numbers of outputs and inputs for each connection. This ensures consistency in the flow of information between the layers.\n",
        "\n",
        "* Additionally, the forward method plays a crucial role in linking all the layers together in the correct order. By properly connecting the layers, the **forward** method ensures that the data is propagated through the network in a sequential and meaningful way, ultimately leading to accurate predictions or classifications."
      ],
      "metadata": {
        "id": "FTwZkaSG58Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Read the dataset.\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/forestfires.csv\",\n",
        "    na_values=['NA', '?'])\n",
        "\n",
        "loc1 = df['X']\n",
        "loc2 = df['Y']\n",
        "\n",
        "# Handle missing value\n",
        "df['rain'] = df['rain'].fillna(df['rain'].median())\n",
        "\n",
        "# Pandas to Numpy\n",
        "x = df[['X', 'Y', 'DC', 'FFMC', 'DMC', 'rain', 'ISI',\n",
        "       'temp', 'RH', 'wind']].values\n",
        "y = df['area'].values # target values\n",
        "\n",
        "# Numpy to PyTorch\n",
        "x = torch.tensor(x,device=device,dtype=torch.float32)\n",
        "y = torch.tensor(y,device=device,dtype=torch.float32)"
      ],
      "metadata": {
        "id": "iGKGcopj6YHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To load the CSV file, Pandas is used as demonstrated before.  **In cases where the  values are missing, the median value is used as a substitute.** **The data is then converted from Pandas to NumPy, and subsequently from NumPy to PyTorch**. Only the selected fields that will be used for prediction are retained. The Net class is designed to automatically adjust the number of input neurons based on the size of this data.\n",
        "\n",
        "With the data loaded and prepared, it is time to create the neural network, loss function, and optimizer class to facilitate the training process."
      ],
      "metadata": {
        "id": "4wSdgfMV7OJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "model = Net(x.shape[1],1).to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Define the loss function for regression\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "Au8lIKJ97QLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network is created using the size of input, which is equal to the number of columns in the x-input data. One output neuron is specified to predict the value. For the error function, we use MSELoss, which is commonly used for regression tasks. The Adam optimizer is chosen with a learning rate of 0.01 for training the network. Adam is a popular optimizer, and 0.01 is a reasonable initial learning rate. It's important to note that the learning rate should not exceed 1.0. If the learning rate is too high, the network may fail to learn effectively, while a very low learning rate would result in slow training. Advanced methods for determining the optimal learning rate, such as learning rate schedules, will be covered later.\n",
        "\n",
        "With all the necessary objects created, we can now proceed to train the neural network."
      ],
      "metadata": {
        "id": "8AEfxapL7jAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 10000 epochs.\n",
        "for epoch in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x).flatten()\n",
        "    loss = loss_fn(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "# Assignment: go through the above code, make a short note for yourself,\n",
        "\n",
        "    # Display status every 100 epochs.\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOP8p-WB7kCe",
        "outputId": "8c328332-b7f8-45a2-c050-f1d692dcd658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 4834.59033203125\n",
            "Epoch 100, loss: 3951.263916015625\n",
            "Epoch 200, loss: 3730.614990234375\n",
            "Epoch 300, loss: 3426.549560546875\n",
            "Epoch 400, loss: 2882.23291015625\n",
            "Epoch 500, loss: 2514.11279296875\n",
            "Epoch 600, loss: 2926.951904296875\n",
            "Epoch 700, loss: 2068.617431640625\n",
            "Epoch 800, loss: 1684.3121337890625\n",
            "Epoch 900, loss: 2454.193115234375\n",
            "Epoch 1000, loss: 1812.0714111328125\n",
            "Epoch 1100, loss: 1433.5450439453125\n",
            "Epoch 1200, loss: 1291.8984375\n",
            "Epoch 1300, loss: 1191.12939453125\n",
            "Epoch 1400, loss: 1025.2928466796875\n",
            "Epoch 1500, loss: 869.455322265625\n",
            "Epoch 1600, loss: 737.9486694335938\n",
            "Epoch 1700, loss: 600.3748779296875\n",
            "Epoch 1800, loss: 1428.8013916015625\n",
            "Epoch 1900, loss: 472.2813720703125\n",
            "Epoch 2000, loss: 426.26055908203125\n",
            "Epoch 2100, loss: 399.2085876464844\n",
            "Epoch 2200, loss: 381.314697265625\n",
            "Epoch 2300, loss: 368.8194885253906\n",
            "Epoch 2400, loss: 363.4410095214844\n",
            "Epoch 2500, loss: 349.96881103515625\n",
            "Epoch 2600, loss: 342.708740234375\n",
            "Epoch 2700, loss: 336.1187744140625\n",
            "Epoch 2800, loss: 335.72613525390625\n",
            "Epoch 2900, loss: 327.1569519042969\n",
            "Epoch 3000, loss: 316.0871276855469\n",
            "Epoch 3100, loss: 308.63385009765625\n",
            "Epoch 3200, loss: 299.2721252441406\n",
            "Epoch 3300, loss: 295.3200988769531\n",
            "Epoch 3400, loss: 292.18865966796875\n",
            "Epoch 3500, loss: 295.5262451171875\n",
            "Epoch 3600, loss: 277.04034423828125\n",
            "Epoch 3700, loss: 291.1337585449219\n",
            "Epoch 3800, loss: 272.4224548339844\n",
            "Epoch 3900, loss: 299.4659423828125\n",
            "Epoch 4000, loss: 263.3263854980469\n",
            "Epoch 4100, loss: 264.4035339355469\n",
            "Epoch 4200, loss: 250.67807006835938\n",
            "Epoch 4300, loss: 270.2786865234375\n",
            "Epoch 4400, loss: 252.62391662597656\n",
            "Epoch 4500, loss: 239.17709350585938\n",
            "Epoch 4600, loss: 3465.65380859375\n",
            "Epoch 4700, loss: 3213.6728515625\n",
            "Epoch 4800, loss: 3075.11669921875\n",
            "Epoch 4900, loss: 2919.31298828125\n",
            "Epoch 5000, loss: 2680.576416015625\n",
            "Epoch 5100, loss: 2403.5126953125\n",
            "Epoch 5200, loss: 2186.287109375\n",
            "Epoch 5300, loss: 1992.9014892578125\n",
            "Epoch 5400, loss: 1830.8946533203125\n",
            "Epoch 5500, loss: 1751.472900390625\n",
            "Epoch 5600, loss: 1591.1925048828125\n",
            "Epoch 5700, loss: 1507.8065185546875\n",
            "Epoch 5800, loss: 1391.20556640625\n",
            "Epoch 5900, loss: 1374.9110107421875\n",
            "Epoch 6000, loss: 1138.537841796875\n",
            "Epoch 6100, loss: 1122.2989501953125\n",
            "Epoch 6200, loss: 1042.58642578125\n",
            "Epoch 6300, loss: 862.91552734375\n",
            "Epoch 6400, loss: 791.2080078125\n",
            "Epoch 6500, loss: 750.9793090820312\n",
            "Epoch 6600, loss: 779.0429077148438\n",
            "Epoch 6700, loss: 650.3721923828125\n",
            "Epoch 6800, loss: 926.9841918945312\n",
            "Epoch 6900, loss: 567.1134643554688\n",
            "Epoch 7000, loss: 708.6221313476562\n",
            "Epoch 7100, loss: 522.10498046875\n",
            "Epoch 7200, loss: 510.8468017578125\n",
            "Epoch 7300, loss: 532.3937377929688\n",
            "Epoch 7400, loss: 451.5841369628906\n",
            "Epoch 7500, loss: 474.0310974121094\n",
            "Epoch 7600, loss: 546.9043579101562\n",
            "Epoch 7700, loss: 446.3150939941406\n",
            "Epoch 7800, loss: 416.72344970703125\n",
            "Epoch 7900, loss: 446.1048889160156\n",
            "Epoch 8000, loss: 424.5031433105469\n",
            "Epoch 8100, loss: 384.74639892578125\n",
            "Epoch 8200, loss: 497.93975830078125\n",
            "Epoch 8300, loss: 435.5907287597656\n",
            "Epoch 8400, loss: 379.28955078125\n",
            "Epoch 8500, loss: 381.8655700683594\n",
            "Epoch 8600, loss: 373.7005615234375\n",
            "Epoch 8700, loss: 545.8971557617188\n",
            "Epoch 8800, loss: 405.08721923828125\n",
            "Epoch 8900, loss: 365.1636962890625\n",
            "Epoch 9000, loss: 372.7760314941406\n",
            "Epoch 9100, loss: 351.173095703125\n",
            "Epoch 9200, loss: 377.78363037109375\n",
            "Epoch 9300, loss: 382.14398193359375\n",
            "Epoch 9400, loss: 328.4698181152344\n",
            "Epoch 9500, loss: 402.76361083984375\n",
            "Epoch 9600, loss: 338.8416748046875\n",
            "Epoch 9700, loss: 365.5824890136719\n",
            "Epoch 9800, loss: 343.477294921875\n",
            "Epoch 9900, loss: 317.5401306152344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the training process, we iterate over 10,000 epochs, where each epoch represents a complete pass over the training set. At the start of each epoch, we zero the gradients to ensure that the gradients from the previous epoch don't influence the current epoch's training. The entire training set is presented to the model as one large batch. In more advanced techniques, we'll explore different ways to segment the data for training.\n",
        "\n",
        "During each epoch, we apply the loss function to calculate the loss between the predicted output and the actual target values. Then, using backpropagation, we compute the gradients of the loss with respect to the network weights. These gradients are used to update the weights, making incremental adjustments to improve the network's performance."
      ],
      "metadata": {
        "id": "j2Jop9Aj7zyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing Hyperparameters of the network\n",
        "\n",
        "\n",
        "The neural network consists of multiple hidden layers, with varying numbers of neurons such as 50 and 25. The decision on the number of neurons in each layer is a common concern in neural networks. Unfortunately, there is no definitive answer as it depends on the specific problem and data. These choices are known as hyperparameters, which significantly impact the performance of the neural network, yet there is no universally agreed-upon method for setting them.\n",
        "\n",
        "Generally, having more hidden neurons enhances the network's ability to handle complex problems. However, excessive neurons can lead to overfitting and longer training times. On the other hand, too few neurons can result in underfitting and reduced accuracy. Additionally, the number of layers is another hyperparameter to consider. In general, more layers allow the network to perform advanced data preprocessing and feature engineering. However, this comes at the cost of increased training time and the risk of overfitting. It is common to observe a pattern where the number of neurons starts higher near the input layer and gradually decreases towards the output layer, forming a triangular shape."
      ],
      "metadata": {
        "id": "Uz-GJYm477NU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Giving the Prediction value\n",
        "\n",
        "We will proceed with making real predictions. The program will store these predictions in the variable \"**pred**\". These predictions represent the values estimated by the neural network. It's worth noting that the shape of \"**pred**\" is a 2D array. You can always determine the dimensions of the output by printing **\"pred.shape**\". Neural networks have the capability to produce multiple outputs, hence the array format. In this case, the neural network generates only one value per prediction Nonetheless, a 2D array is used to accommodate the possibility of multiple values being returned by the neural network.\n"
      ],
      "metadata": {
        "id": "cTrd2WFV_wVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(x)\n",
        "print(f\"Shape: {pred.shape}\")\n",
        "print(pred[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-N8gvRQAOhQ",
        "outputId": "bb545046-280e-4cba-8966-d66edd6c86f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([517, 1])\n",
            "tensor([[  6.9087],\n",
            "        [-12.3645],\n",
            "        [-22.4224],\n",
            "        [  7.3321],\n",
            "        [ -3.2382],\n",
            "        [  9.2181],\n",
            "        [  6.4532],\n",
            "        [ -3.3428],\n",
            "        [  0.9024],\n",
            "        [ -8.4254]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the accuracy of the predictions, we need to compare the predicted values to the actual  values. This allows us to measure how closely the neural network estimated the values. One way to assess this is by calculating the Root Mean Square Error (RMSE) using the Sklearn library. However, before using Sklearn, we need to bring the predictions back to the CPU and detach them from the neural network graph. The code snippet below demonstrates how to achieve this using \"**cpu().detach()**\"."
      ],
      "metadata": {
        "id": "s-C0S7_ZAZh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(),\n",
        "  y.cpu().detach()))\n",
        "print(f\"Final score (RMSE): {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsdbasrjAdSO",
        "outputId": "162b8c17-b55e-492e-d645-f70432413125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score (RMSE): 44.817604064941406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be also done in easier way in coddign using just PyTorch:"
      ],
      "metadata": {
        "id": "7mbls49fBTXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = torch.sqrt(torch.nn.functional.mse_loss(pred.flatten(),y))\n",
        "print(f\"Final score (RMSE): {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNaGHIUzBZ5k",
        "outputId": "8ac70e4c-2e8a-4a08-e327-c1fc45fb53d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score (RMSE): 21.260713577270508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample predictions\n",
        "for i in range(10):\n",
        "    print(f\"{i+1}. XY: {loc1[i]}, {loc2[i]}, areas: {y[i]}, \"\n",
        "          + f\"predicted area: {pred[i]}\")"
      ],
      "metadata": {
        "id": "IZm7hk5YD4wx",
        "outputId": "195697da-a1ab-4c1e-e58d-ce5164f1223e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. XY: 7, 5, areas: 0.0, predicted area: tensor([6.9087], grad_fn=<SelectBackward0>)\n",
            "2. XY: 7, 4, areas: 0.0, predicted area: tensor([-12.3645], grad_fn=<SelectBackward0>)\n",
            "3. XY: 7, 4, areas: 0.0, predicted area: tensor([-22.4224], grad_fn=<SelectBackward0>)\n",
            "4. XY: 8, 6, areas: 0.0, predicted area: tensor([7.3321], grad_fn=<SelectBackward0>)\n",
            "5. XY: 8, 6, areas: 0.0, predicted area: tensor([-3.2382], grad_fn=<SelectBackward0>)\n",
            "6. XY: 8, 6, areas: 0.0, predicted area: tensor([9.2181], grad_fn=<SelectBackward0>)\n",
            "7. XY: 8, 6, areas: 0.0, predicted area: tensor([6.4532], grad_fn=<SelectBackward0>)\n",
            "8. XY: 8, 6, areas: 0.0, predicted area: tensor([-3.3428], grad_fn=<SelectBackward0>)\n",
            "9. XY: 8, 6, areas: 0.0, predicted area: tensor([0.9024], grad_fn=<SelectBackward0>)\n",
            "10. XY: 7, 5, areas: 0.0, predicted area: tensor([-8.4254], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    }
  ]
}